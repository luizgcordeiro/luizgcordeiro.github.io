<!DOCTYPE html>
<html>
<head>
<meta name='viewport' content='width=device-width'>
<script src='https://polyfill.io/v3/polyfill.min.js?features=es6'></script>
<script id='MathJax-script' async
src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'>
</script>
</head>
<body>

<p>
Recorde que, se \(T\colon V\to W\) é uma transformação linear, denotamos por \([T]_{\mathcal{B}}^{\mathcal{C}}\) a <a href='http://mtm.ufsc.br/~cordeiro/ensino/mtm3112.algebra.linear/15.matrizes.trans.lin/con_rep_matr_trans_lin_moodle.html'>matriz de \(T\)</a> relativa às <a href='../14.iso.lin/con_base_ord_moodle.html'>bases ordenadas</a> \(\mathcal{B}\) e \(\mathcal{C}\) de \(V\) e \(W\), respectivamente, e por \([v]^{\mathcal{B}}\) o <a href='../14.iso.lin/con_vetor_coordenada_moodle.html'>vetor coordenada</a> de um elemento de \(V\) com respeito à base ordenada \(\mathcal{B}\) (e similarmente \([w]^{\mathcal{C}}\) para \(w\in W\)).
</p>

<div style='margin-bottom: 5px; margin-top: 5px; padding: 5px 5px 0 5px; border: 1px solid gray; border-radius: 5px;'>
<b>Teorema</b>.
<p>
Sejam \(V\) e \(W\) espaços vetoriais de dimensão finita, com \(\dim(V)=n\) e \(\dim(W)=m\). Sejam \(\mathcal{B}=\left\{v_1,\ldots,v_n\right\}\) e \(\mathcal{C}=\left\{w_1,\ldots,w_m\right\}\) bases ordenadas de \(V\) e de \(W\), respectivamente.
</p>

<ol>

<li>
<p>
Para toda transformação linear \(T\colon V\to W\) e para todo vetor \(v\in V\), vale que
<div>
\begin{equation*}
[T(v)]^{\mathcal{C}}=[T]_{\mathcal{B}}^{\mathcal{C}}[v]^{\mathcal{B}},
\end{equation*}
</div>
em que o produto na direita é o produto de matrizes.
</p>

</li>

<li>
<p>
Para toda matriz \(A\in M_{m\times n}(\mathbb{R})\), existe uma única transformação linear \(T\colon V\to W\) tal que \([T]_{\mathcal{B}}^{\mathcal{C}}=A\).
</p>

</li>

<li>
<p>
Seja \(\operatorname{L}(V,W)\) o <a href='../15.matrizes.trans.lin/con_soma_mult_trans_lin_moodle.html'>espaço vetorial das transformações lineares</a> de \(V\) em \(W\). Então a aplicação
<div>
\begin{equation*}
\operatorname{L}(V,W)\to M_{m\times n}(\mathbb{R}),\qquad T\mapsto [T]_{\mathcal{B}}^{\mathcal{C}}
\end{equation*}
</div>
é um <a href='../14.iso.lin/con_iso_moodle.html'>isomorfismo linear</a>.
</p>

</li>

<li>
<p>
Se \(U\) é um outro espaço vetorial com uma base ordenada \(\mathcal{D}=\left\{u_1,\ldots,u_l\right\}\), e \(T\colon V\to W\) e \(S\colon W\to U\) são transformações lineares, então vale que
<div>
\begin{equation*}
[S\circ T]_{\mathcal{B}}^{\mathcal{D}}=[S]_{\mathcal{C}}^{\mathcal{D}}[T]_{\mathcal{B}}^{\mathcal{C}},
\end{equation*}
</div>
em que o produto na direita é o produto de matrizes.
</p>

</li>
</ol>

</div>

<div style='margin-bottom: 5px; margin-top: 5px; padding: 5px 5px 0 5px; border: 1px solid gray; border-radius: 5px;'>
<i>Prova</i>.

<ol>

<li>
<p>
Sejam \(T\colon V\to W\) uma transformação linear e \(v\) um vetor em \(V\). Primeiro, escrevemos \(v\) como uma combinação linear dos elementos de \(\mathcal{B}\):
<div>
\begin{equation*}
v=\lambda_1 v_1+\cdots+\lambda_n v_n,
\end{equation*}
</div>
o que significa que o vetor coordenada de \(v\) na base \(\mathcal{B}\) é dado por
<div>
\begin{equation*}
[v]^{\mathcal{B}}=\begin{bmatrix}\lambda_1\\\vdots\\\lambda_n

\end{bmatrix}.
\end{equation*}
</div>
Considere a matriz de \(T\) relavia às bases \(\mathcal{B}\) e \(\mathcal{C}\), \([T]_{\mathcal{B}}^{\mathcal{C}}=[t_{ij}]_{ij}\). Isto significa que para cada \(i\) e cada \(j\), \(t_{ij}\) é a \(i\)-ésima coordenada de \(T(v_j)\).
</p>
<p>
Assim
<div>
\begin{align*}
T(v)
&=T\left(\sum_j\lambda_j v_j\right)\\
&=\sum_j\lambda_j T(v_j)\\
&=\sum_j\sum_i\lambda_j t_{ij}w_i\\
&=\sum_i\left(\sum_j \lambda_j t_{ij}\right)w_i.
\end{align*}
</div>
Isto significa que a \(i\)-ésima coordenada de \(T(v)\) na base \(\mathcal{C}\) é dada por \(\sum_j\lambda_j t_{ij}\). Portanto,
<div>
\begin{equation*}
[T(v)]^{\mathcal{C}}=\begin{bmatrix}\sum_j\lambda_j t_{1j}\\\vdots\\\sum_j\lambda_j t_{mj}

\end{bmatrix}.\tag{1}
\end{equation*}
</div>
Por outro lado,
<div>
\begin{align*}
[T]_{\mathcal{B}}^{\mathcal{C}}[v]^{\mathcal{B}}
&=\begin{bmatrix}t_{11}&\cdots&t_{1n}\\\vdots&\ddots&\vdots\\t_{m1}&\cdots&t_{mn}

\end{bmatrix}\begin{bmatrix}\lambda_1\\\vdots\\\lambda_n

\end{bmatrix}=\begin{bmatrix}\sum_j t_{1j}\lambda_j\\\vdots\\\sum_j t_{mj}\lambda_j

\end{bmatrix}.\tag{2}
\end{align*}
</div>
Como os vetores coluna dos lados direitos das equações (1) e (2) coincidem, isto prova que \([T(v)]^{\mathcal{C}}=[T]_{\mathcal{B}}^{\mathcal{C}}[v]^{\mathcal{B}}\).
</p>

</li>

<li>
<p>
Seja \(A\in M_{m\times n}(\mathbb{R})\) uma matriz \(m\times n\). Para construir uma transformação linear \(T\) cuja representação respectiva às bases \(\mathcal{B}\) e \(\mathcal{C}\) seja dada por \(A\), notemos o seguinte: Caso tenhamos tal \(T\), então a \(j\)-ésima coluna de \(A\) será o vetor coluna das coordenadas de \(T(v_j)\) com relação à base \(\mathcal{C}\), o que significa que procuramos \(T\colon V\to W\) tal que
<div>
\begin{equation*}
T(v_j)=\sum_i a_{ij}w_i\qquad\text{para todo }j.\tag{3}
\end{equation*}
</div>
Como transformações lineares estão unicamente determinadas por seus valores na base \(\mathcal{B}\), existe exatamente uma transformação linear \(T\colon V\to W\) satisfazendo (3), ou equivalentemente que \([T]_{\mathcal{B}}^{\mathcal{C}}=A\).
</p>

</li>

<li>
<p>
A aplicação \(T\mapsto [T]_{\mathcal{B}}^{\mathcal{C}}\) é bijetiva pelo item anterior. A verificação de que esta aplicação é linear (e portanto um isomorfismo linear) é rotineira: Se \(T_1,T_2\in\operatorname{L}(V,W)\) e \(\lambda\in\mathbb{R}\), então temos que
<div>
\begin{align*}
[T_1+\lambda T_2]_{\mathcal{B}}^{\mathcal{C}}
&\overset{(1)}{=}\begin{bmatrix}|&&|\\ [(T_1+\lambda T_2)(v_1)]^{\mathcal{C}}&\cdots&[(T_1+\lambda T_2)(v_n)]^{\mathcal{C}}\\|&&|

\end{bmatrix}\\
&\overset{(2)}{=}\begin{bmatrix}|&&|\\ [T_1(v_1)+\lambda T_2(v_1)]^{\mathcal{C}}&\cdots&[T_1(v_n)+\lambda T_2(v_n)]^{\mathcal{C}}\\|&&|

\end{bmatrix}\\
&\overset{(3)}{=}\begin{bmatrix}|&&|\\ [T_1(v_1)]^{\mathcal{C}}+\lambda [T_2(v_1)]^{\mathcal{C}}&\cdots&[T_1(v_n)]^{\mathcal{C}}+\lambda[T_2(v_n)]^{\mathcal{C}}\\|&&|

\end{bmatrix}\\
&\overset{(4)}{=}\begin{bmatrix}|&&|\\ [T_1(v_1)]^{\mathcal{C}}&\cdots&[T_1(v_n)]^{\mathcal{C}}\\|&&|

\end{bmatrix}+\lambda\begin{bmatrix}|&&|\\ [T_2(v_1)]^{\mathcal{C}}&\cdots&[T_2(v_n)]^{\mathcal{C}}\\|&&|

\end{bmatrix}\\
&\overset{(5)}{=}[T_1]_{\mathcal{B}}^{\mathcal{C}}+\lambda[T_2]_{\mathcal{B}}^{\mathcal{C}}.
\end{align*}
</div>
onde
</p>

<ul>

</li>

<li>

(1) é a definição de matriz associada a uma transformação linear;

</li>

<li>

(2) é a definição de soma e multiplicação por escalar para transformações lineares;

</li>

<li>

(3) segue do fato que a função de \(W\) a \(M_{m\times 1}(\mathbb{R})\), que associa a cada vetor \(w\) seu vetor coordenada \([w]^{\mathcal{C}}\) na base \(\mathcal{C}\), é linear;

</li>

<li>

(4) é a definição de soma e multiplicação por escalar para matrizes;

</li>

<li>

(5) é novamente a definição de matrizes associadas a transformações lineares.

</li>
</ul>
<p>
Isto prova que a função \(T\mapsto [T]_{\mathcal{B}}^{\mathcal{C}}\) é linear.
</p>

<li>
<p>
Sejam \(S\) e \(T\) como no enunciado, com as respectivas matrizes \([S]_{\mathcal{C}}^{\mathcal{D}}=[s_{li}]_{li}\) e \([T]_{\mathcal{B}}^{\mathcal{C}}=[t_{ij}]_{ij}\). Vamos calcular a \(j\)-ésima coluna de \([S\circ T]_{\mathcal{B}}^{\mathcal{D}}\).
<div>
\begin{align*}
(S\circ T)(v_j)
&=S(T(v_j))\\
&=S\left(\sum_i t_{ij}w_i\right)\\
&=\sum_i t_{ij}S(w_i)\\
&=\sum_it_{ij}\sum_ks_{ki}u_k\\
&=\sum_k\left(\sum_is_{ki}t_{ij}\right)u_k.
\end{align*}
</div>
Isto significa que a entrada \((k,j)\) da matriz \([S\circ T]_{\mathcal{B}}^{\mathcal{D}}\) é dada por \(\sum_is_{ki}t_{ij}\). Este é exatamente o valor da mesma entrada \((k,j)\) da matriz produto \([s_{ki}]_{ki}[t_{ij}]_{ij}=[S]_{\mathcal{C}}^{\mathcal{D}}[T]_{\mathcal{B}}^{\mathcal{C}}\).
</p>
<p>
Concluímos que as matrizes \([S\circ T]_{\mathcal{B}}^{\mathcal{D}}\) e \([S]_{\mathcal{C}}^{\mathcal{D}}[T]_{\mathcal{B}}^{\mathcal{C}}\) são iguais
</p>

</li>
</ol>

</div></body>
</html>
